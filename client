import pandas as pd
import numpy as np
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone
from jellyfish import soundex
from sklearn.model_selection import train_test_split

class NameMatchingModel:
    def __init__(self, model=None):
        self.model = model or RandomForestClassifier(random_state=42)
        self.titles = {'dr', 'mr', 'mrs', 'ms', 'ph.d.', 'professor', 'sir', 'lady', 'captain', 'major'}

    # Preprocessing functions
    def normalize_name(self, name):
        return str(name).lower().replace(".", "").replace("-", "").replace(",", "").strip()

    def remove_titles(self, name):
        parts = self.normalize_name(name).split()
        return ' '.join(part for part in parts if part not in self.titles)

    def phonetic_encoding(self, name):
        encoded = doublemetaphone(name)
        return encoded[0] if encoded[0] else encoded[1]

    def soundex_encoding(self, name):
        return soundex(name)

    def extract_initials(self, name):
        parts = name.split()
        return [part[0] for part in parts]

    def initials_match(self, name1, name2):
        initials1 = set(self.extract_initials(name1))
        initials2 = set(self.extract_initials(name2))
        return initials1 == initials2

    def approximate_nickname_match(self, name1, name2):
        if len(name1) < len(name2):
            shorter, longer = name1, name2
        else:
            shorter, longer = name2, name1

        start_match = fuzz.partial_ratio(shorter, longer) >= 60
        phonetic_match = self.phonetic_encoding(shorter) == self.phonetic_encoding(longer[:len(shorter)])
        return start_match or phonetic_match

    def has_common_components(self, name1, name2):
        components1 = set(name1.split())
        components2 = set(name2.split())
        return components1.issubset(components2) or components2.issubset(components1)

    # Similarity calculation function
    def calculate_similarities(self, name1, name2):
        name1, name2 = self.normalize_name(name1), self.normalize_name(name2)
        name1_no_titles = self.remove_titles(name1)
        name2_no_titles = self.remove_titles(name2)

        if self.initials_match(name1_no_titles, name2_no_titles):
            return 1.0
        if self.approximate_nickname_match(name1_no_titles, name2_no_titles):
            return 1.0
        if self.has_common_components(name1_no_titles, name2_no_titles):
            return 0.9
        if sorted(name1_no_titles.split()) == sorted(name2_no_titles.split()):
            return 0.9

        phonetic_sim = fuzz.ratio(self.phonetic_encoding(name1_no_titles), self.phonetic_encoding(name2_no_titles)) / 100.0
        levenshtein_sim = fuzz.ratio(name1_no_titles, name2_no_titles) / 100.0
        jaro_winkler_sim = fuzz.token_sort_ratio(name1_no_titles, name2_no_titles) / 100.0
        soundex_sim = 1.0 if self.soundex_encoding(name1_no_titles) == self.soundex_encoding(name2_no_titles) else 0.0

        vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
        ngram_matrix = vectorizer.fit_transform([name1_no_titles, name2_no_titles])
        cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]

        def jaccard_similarity(name1, name2):
            set1, set2 = set(name1.split()), set(name2.split())
            return len(set1.intersection(set2)) / len(set1.union(set2))

        jaccard_sim = jaccard_similarity(name1_no_titles, name2_no_titles)

        weighted_score = (0.3 * phonetic_sim +
                          0.3 * levenshtein_sim +
                          0.4 * jaro_winkler_sim +
                          0.4 * cosine_sim +
                          0.1 * jaccard_sim +
                          0.2 * soundex_sim)

        return weighted_score

    # Training and saving methods
    def prepare_training_data(self, df):
        X, y = [], []
        for _, row in df.iterrows():
            name1, name2 = row['Name1'], row['Name2']
            score = self.calculate_similarities(name1, name2)
            X.append([score])
            y.append(row['Actual Label'])
        return np.array(X), np.array(y)

    def train_model(self, data):
        matched_df = self.match_names_from_excel(data, threshold=0.6)
        matched_df['Actual Label'] = data['Label']
        X, y = self.prepare_training_data(matched_df)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        self.model.fit(X_train, y_train)

    def save_model(self, filename='name_matching_model.pkl'):
        with open(filename, 'wb') as file:
            pickle.dump(self, file)
        print(f"Model saved as {filename}")

    # Prediction methods
    def match_names_from_excel(self, data, threshold=0.6):
        results = []
        for _, row in data.iterrows():
            name1, name2 = row['Name1'], row['Name2']
            score = self.calculate_similarities(name1, name2)
            label = 1 if score >= threshold else 0
            results.append((name1, name2, score, label))
        return pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])

    def batch_predict_similarity(self, input_file, output_file, threshold=0.6):
        data = pd.read_excel(input_file)
        results = []
        for _, row in data.iterrows():
            name1, name2 = row['Name1'], row['Name2']
            score = self.calculate_similarities(name1, name2)
            label = 1 if score >= threshold else 0
            results.append((name1, name2, round(score, 2), label))
        results_df = pd.DataFrame(results, columns=['Name1', 'Name2', 'Similarity Score', 'Predicted Label'])
        results_df.to_excel(output_file, index=False)
        print(f"Results saved to {output_file}")

# Saving the model
name_match_model = NameMatchingModel()
name_match_model.train_model(pd.read_excel('Mathwizzathon_Entity_Matching_Dataset.xlsx'))
name_match_model.save_model()

============================================================================================

import pandas as pd
import pickle

# Load the model
with open('name_matching_model.pkl', 'rb') as file:
    model = pickle.load(file)

# Specify input and output files
input_file = 'input_names.xlsx'  # Path to input Excel file
output_file = 'output_predictions.xlsx'  # Path for output Excel file

# Run batch predictions
model.batch_predict_similarity(input_file, output_file, threshold=0.6)
print(f"Predictions saved to {output_file}")

