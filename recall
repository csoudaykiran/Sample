import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'Mathwizzathon_Entity_Matching_Dataset.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# List of common titles and honorifics to ignore
titles = {'dr', 'mr', 'mrs', 'ms', 'ph.d.', 'professor', 'sir', 'lady', 'captain', 'major'}

# Preprocessing functions
def normalize_name(name):
    return str(name).lower().replace(".", "").replace("-", "").replace(",", "").strip()

def remove_titles(name):
    parts = normalize_name(name).split()
    return ' '.join(part for part in parts if part not in titles)

def phonetic_encoding(name):
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

def jaccard_similarity(name1, name2):
    set1, set2 = set(name1.split()), set(name2.split())
    return len(set1.intersection(set2)) / len(set1.union(set2))

# Similarity functions
def calculate_similarities(name1, name2):
    name1, name2 = remove_titles(name1), remove_titles(name2)

    # Calculate similarity features
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0
    levenshtein_sim = fuzz.ratio(name1, name2) / 100.0
    jaro_winkler_sim = fuzz.token_sort_ratio(name1, name2) / 100.0

    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1, name2])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]
    
    jaccard_sim = jaccard_similarity(name1, name2)

    # Return as a feature vector
    return [phonetic_sim, levenshtein_sim, jaro_winkler_sim, cosine_sim, jaccard_sim]

# Prepare feature matrix and labels
X = []
y = []
for _, row in data.iterrows():
    name1, name2, label = row['Name1'], row['Name2'], row['Label']
    X.append(calculate_similarities(name1, name2))
    y.append(label)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest Classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Evaluate on the testing set
y_pred = clf.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
test_precision = precision_score(y_test, y_pred)
test_recall = recall_score(y_test, y_pred)

# Print the performance metrics
print(f"Testing Accuracy: {test_accuracy:.2f}")
print(f"Testing Precision: {test_precision:.2f}")
print(f"Testing Recall: {test_recall:.2f}")

# Save the results to Excel
results_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
output_file_path = 'ml_matched_names_output.xlsx'
results_df.to_excel(output_file_path, index=False)

print(f"Results saved to '{output_file_path}'")


=============================================  old ==================================

import pandas as pd
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'Mathwizzathon_Entity_Matching_Dataset.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# List of common titles and honorifics to ignore
titles = {'dr', 'mr', 'mrs', 'ms', 'ph.d.', 'professor', 'sir', 'lady', 'captain', 'major'}

# Preprocessing functions
def normalize_name(name):
    return str(name).lower().replace(".", "").replace("-", "").replace(",", "").strip()

def remove_titles(name):
    parts = normalize_name(name).split()
    return ' '.join(part for part in parts if part not in titles)

def phonetic_encoding(name):
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

def extract_initials(name):
    parts = name.split()
    return [part[0] for part in parts]

def initials_match(name1, name2):
    initials1 = set(extract_initials(name1))
    initials2 = set(extract_initials(name2))
    return initials1 == initials2

def approximate_nickname_match(name1, name2):
    if len(name1) < len(name2):
        shorter, longer = name1, name2
    else:
        shorter, longer = name2, name1

    start_match = fuzz.partial_ratio(shorter, longer) >= 75
    phonetic_match = phonetic_encoding(shorter) == phonetic_encoding(longer[:len(shorter)])
    return start_match or phonetic_match

def has_common_components(name1, name2):
    components1 = set(name1.split())
    components2 = set(name2.split())
    return components1.issubset(components2) or components2.issubset(components1)

# Similarity functions
def calculate_similarities(name1, name2):
    name1, name2 = normalize_name(name1), normalize_name(name2)
    name1_no_titles = remove_titles(name1)
    name2_no_titles = remove_titles(name2)

    if initials_match(name1_no_titles, name2_no_titles):
        return 1.0

    if approximate_nickname_match(name1_no_titles, name2_no_titles):
        return 1.0

    if has_common_components(name1_no_titles, name2_no_titles):
        return 0.9

    if sorted(name1_no_titles.split()) == sorted(name2_no_titles.split()):
        return 0.9

    phonetic_sim = fuzz.ratio(phonetic_encoding(name1_no_titles), phonetic_encoding(name2_no_titles)) / 100.0
    levenshtein_sim = fuzz.ratio(name1_no_titles, name2_no_titles) / 100.0
    jaro_winkler_sim = fuzz.token_sort_ratio(name1_no_titles, name2_no_titles) / 100.0

    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1_no_titles, name2_no_titles])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]
    
def jaccard_similarity(name1, name2):
    set1, set2 = set(name1.split()), set(name2.split())
    return len(set1.intersection(set2)) / len(set1.union(set2))

# Add Jaccard similarity to the weighted score
jaccard_sim = jaccard_similarity(name1_no_titles, name2_no_titles)
weighted_score = 0.3 * phonetic_sim + 0.3 * levenshtein_sim + 0.39 * jaro_winkler_sim + 0.4 * cosine_sim + 0.1 * jaccard_sim

    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy, precision, and recall
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100
precision = precision_score(matched_df['Actual Label'], matched_df['Predicted Label'])
recall = recall_score(matched_df['Actual Label'], matched_df['Predicted Label'])

# Identify mismatches
mismatches = matched_df[matched_df['Predicted Label'] != matched_df['Actual Label']]

# Print mismatched rows
if not mismatches.empty:
    print("Mismatches between Actual and Predicted Labels:")
    print(mismatches)
else:
    print("All predictions match the actual labels.")

# Save mismatches to a separate Excel file
mismatches_file_path = 'mismatched_names_output.xlsx'
mismatches.to_excel(mismatches_file_path, index=False)

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")
print(f"Mismatched names saved to '{mismatches_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")


=========================================  increased recall ==========================

import pandas as pd
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone
from textdistance import jaccard, dice, monge_elkan, soft_tfidf

# Load data from Excel
file_path = 'Mathwizzathon_Entity_Matching_Dataset.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# List of common titles and honorifics to ignore
titles = {'dr', 'mr', 'mrs', 'ms', 'ph.d.', 'professor', 'sir', 'lady', 'captain', 'major'}

# Preprocessing functions
def normalize_name(name):
    return str(name).lower().replace(".", "").replace("-", "").replace(",", "").strip()

def remove_titles(name):
    parts = normalize_name(name).split()
    return ' '.join(part for part in parts if part not in titles)

def phonetic_encoding(name):
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

def extract_initials(name):
    parts = name.split()
    return [part[0] for part in parts]

def initials_match(name1, name2):
    initials1 = set(extract_initials(name1))
    initials2 = set(extract_initials(name2))
    return initials1 == initials2

def approximate_nickname_match(name1, name2):
    if len(name1) < len(name2):
        shorter, longer = name1, name2
    else:
        shorter, longer = name2, name1
    start_match = fuzz.partial_ratio(shorter, longer) >= 75
    phonetic_match = phonetic_encoding(shorter) == phonetic_encoding(longer[:len(shorter)])
    return start_match or phonetic_match

def has_common_components(name1, name2):
    components1 = set(name1.split())
    components2 = set(name2.split())
    return components1.issubset(components2) or components2.issubset(components1)

# Jaccard similarity on token sets
def jaccard_similarity(name1, name2):
    set1, set2 = set(name1.split()), set(name2.split())
    return len(set1.intersection(set2)) / len(set1.union(set2))

# Enhanced similarity calculation function with additional measures
def calculate_similarities(name1, name2):
    # Normalization and removing titles
    name1, name2 = normalize_name(name1), normalize_name(name2)
    name1_no_titles = remove_titles(name1)
    name2_no_titles = remove_titles(name2)

    # Level 1: Exact match or Initials match
    if initials_match(name1_no_titles, name2_no_titles) or name1_no_titles == name2_no_titles:
        return 1.0

    # Level 2: Nickname or Common Component Match
    if approximate_nickname_match(name1_no_titles, name2_no_titles) or has_common_components(name1_no_titles, name2_no_titles):
        return 0.95

    # Level 3: Substring Matching
    if name1_no_titles in name2_no_titles or name2_no_titles in name1_no_titles:
        return 0.9

    # Calculate phonetic, Levenshtein, Jaro-Winkler, Cosine, and Jaccard similarities
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1_no_titles), phonetic_encoding(name2_no_titles)) / 100.0
    levenshtein_sim = fuzz.ratio(name1_no_titles, name2_no_titles) / 100.0
    jaro_winkler_sim = fuzz.token_sort_ratio(name1_no_titles, name2_no_titles) / 100.0

    # Cosine similarity with character n-grams
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1_no_titles, name2_no_titles])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]

    # Jaccard similarity
    jaccard_sim = jaccard_similarity(name1_no_titles, name2_no_titles)

    # Additional Similarity Measures for Recall Improvement
    dice_sim = dice(name1_no_titles, name2_no_titles)
    monge_elkan_sim = monge_elkan(name1_no_titles.split(), name2_no_titles.split())
    soft_tfidf_sim = soft_tfidf(name1_no_titles.split(), name2_no_titles.split())
    
    # Relaxed threshold matching using Jaccard and Dice for partial matches
    if jaccard_sim > 0.5 or dice_sim > 0.5:
        return 0.85

    # Weighted scoring with new measures
    weighted_score = (
        0.15 * phonetic_sim + 
        0.15 * levenshtein_sim + 
        0.2 * jaro_winkler_sim + 
        0.25 * cosine_sim + 
        0.1 * jaccard_sim + 
        0.1 * dice_sim + 
        0.1 * monge_elkan_sim + 
        0.1 * soft_tfidf_sim
    )

    # Catch-all rule: If other criteria fail but names share significant components
    if weighted_score < 0.6 and has_common_components(name1_no_titles, name2_no_titles):
        return 0.85  # Give higher weight for matching components

    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy, precision, and recall
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100
precision = precision_score(matched_df['Actual Label'], matched_df['Predicted Label'])
recall = recall_score(matched_df['Actual Label'], matched_df['Predicted Label'])

# Identify mismatches
mismatches = matched_df[matched_df['Predicted Label'] != matched_df['Actual Label']]

# Print mismatched rows
if not mismatches.empty:
    print("Mismatches between Actual and Predicted Labels:")
    print(mismatches)
else:
    print("All predictions match the actual labels.")

# Save mismatches to a separate Excel file
mismatches_file_path = 'mismatched_names_output.xlsx'
mismatches.to_excel(mismatches_file_path, index=False)

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'
matched_df.to_excel(output_file_path, index=False)

# Output metrics
print(f"Matched names saved to '{output_file_path}'")
print(f"Mismatched names saved to '{mismatches_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")


======================================  rnd =========================================

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Load data from Excel
file_path = 'Mathwizzathon_Entity_Matching_Dataset.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    return str(name).lower().replace(".", "").replace("-", "").replace(",", "").strip()

def phonetic_encoding(name):
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

# Feature extraction function
def generate_features(name1, name2):
    name1, name2 = normalize_name(name1), normalize_name(name2)
    features = {
        'phonetic_sim': fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0,
        'levenshtein_sim': fuzz.ratio(name1, name2) / 100.0,
        'jaro_winkler_sim': fuzz.token_sort_ratio(name1, name2) / 100.0,
        'cosine_sim': cosine_similarity(
            CountVectorizer(analyzer='char', ngram_range=(2, 3)).fit_transform([name1, name2])[0:1],
            CountVectorizer(analyzer='char', ngram_range=(2, 3)).fit_transform([name1, name2])[1:2])[0][0]
    }
    return list(features.values())

# Prepare feature matrix and labels
X = []
y = []
for _, row in data.iterrows():
    name1, name2, label = row['Name1'], row['Name2'], row['Label']
    X.append(generate_features(name1, name2))
    y.append(label)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the RandomForestClassifier with class weights to improve recall
clf = RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=42)
clf.fit(X_train, y_train)

# Adjust the decision threshold for recall optimization
y_test_proba = clf.predict_proba(X_test)[:, 1]
threshold = 0.4  # Adjust this to a lower value for higher recall
y_test_pred = (y_test_proba >= threshold).astype(int)

# Evaluate performance on the testing set
test_accuracy = accuracy_score(y_test, y_test_pred)
test_precision = precision_score(y_test, y_test_pred)
test_recall = recall_score(y_test, y_test_pred)

# Print testing metrics
print(f"Testing Accuracy: {test_accuracy * 100:.2f}%")
print(f"Testing Precision: {test_precision * 100:.2f}%")
print(f"Testing Recall: {test_recall * 100:.2f}%")
