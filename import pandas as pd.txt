!pip install nltk scikit-learn fuzzywuzzy python-Levenshtein soundex metaphone

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'your_file.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    # Convert to lowercase, remove punctuations, extra spaces, etc.
    name = str(name).lower().replace(".", "").replace("-", "").replace(",", "")
    return name.strip()

def phonetic_encoding(name):
    # Using Double Metaphone for phonetic similarity
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

# Similarity functions
def calculate_similarities(name1, name2):
    # Normalize names
    name1, name2 = normalize_name(name1), normalize_name(name2)
    
    # Phonetic similarity
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0
    
    # Edit distance similarity (Levenshtein)
    levenshtein_sim = fuzz.ratio(name1, name2) / 100.0
    
    # Jaro-Winkler similarity
    jaro_winkler_sim = fuzz.token_sort_ratio(name1, name2) / 100.0

    # Cosine similarity on character n-grams
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1, name2])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]
    
    # Weighted similarity score
    weighted_score = 0.3 * phonetic_sim + 0.3 * levenshtein_sim + 0.2 * jaro_winkler_sim + 0.2 * cosine_sim
    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.75):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        actual_label = row['Label']
        score = calculate_similarities(name1, name2)
        predicted_match = 1 if score >= threshold else 0
        results.append((name1, name2, score, predicted_match, actual_label))
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Match", "Actual Label"])
    return results_df

# Run the matching
matched_df = match_names_from_excel(data, threshold=0.75)

# Display results
print("Matched Names:")
print(matched_df)

# Calculate accuracy if Label column exists
if 'Label' in matched_df.columns:
    accuracy = (matched_df['Predicted Match'] == matched_df['Actual Label']).mean() * 100
    print(f"Accuracy: {accuracy:.2f}%")



================================= Code 2 ==================================

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'your_file.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    # Convert to lowercase, remove punctuations, extra spaces, etc.
    name = str(name).lower().replace(".", "").replace("-", "").replace(",", "")
    return name.strip()

def phonetic_encoding(name):
    # Using Double Metaphone for phonetic similarity
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

# Similarity functions
def calculate_similarities(name1, name2):
    # Normalize names
    name1, name2 = normalize_name(name1), normalize_name(name2)
    
    # Phonetic similarity
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0
    
    # Edit distance similarity (Levenshtein)
    levenshtein_sim = fuzz.ratio(name1, name2) / 100.0
    
    # Jaro-Winkler similarity
    jaro_winkler_sim = fuzz.token_sort_ratio(name1, name2) / 100.0

    # Cosine similarity on character n-grams
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1, name2])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]
    
    # Weighted similarity score
    weighted_score = 0.3 * phonetic_sim + 0.3 * levenshtein_sim + 0.2 * jaro_winkler_sim + 0.2 * cosine_sim
    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'  # Replace with your desired output file path
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")



================================ Code 3 ======================================

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'your_file.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    # Convert to lowercase, remove punctuations, extra spaces, etc.
    name = str(name).lower().replace(".", "").replace("-", "").replace(",", "")
    return name.strip()

def phonetic_encoding(name):
    # Using Double Metaphone for phonetic similarity
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

# Similarity functions
def calculate_similarities(name1, name2):
    # Normalize names
    name1, name2 = normalize_name(name1), normalize_name(name2)
    
    # Phonetic similarity
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0
    
    # Edit distance similarity (Levenshtein)
    levenshtein_sim = fuzz.ratio(name1, name2) / 100.0
    
    # Jaro-Winkler similarity
    jaro_winkler_sim = fuzz.token_sort_ratio(name1, name2) / 100.0

    # Cosine similarity on character n-grams
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1, name2])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]
    
    # Weighted similarity score
    weighted_score = 0.3 * phonetic_sim + 0.3 * levenshtein_sim + 0.2 * jaro_winkler_sim + 0.2 * cosine_sim
    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'  # Replace with your desired output file path
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")


===================================  code 4 ========================

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone
import re

# Load data from Excel
file_path = 'your_file.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    # Convert to lowercase, remove punctuations, extra spaces, etc.
    name = str(name).lower().replace(".", "").replace("-", "").replace(",", "")
    return name.strip()

def phonetic_encoding(name):
    # Using Double Metaphone for phonetic similarity
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

# Similarity functions
def phonetic_similarity(name1, name2):
    return fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0

def missing_spaces_hyphens(name1, name2):
    # Check if names match after removing spaces and hyphens
    name1_no_spaces = re.sub(r'[\s-]', '', name1)
    name2_no_spaces = re.sub(r'[\s-]', '', name2)
    return 1.0 if name1_no_spaces == name2_no_spaces else 0.0

def spelling_differences(name1, name2):
    # Check for spelling variations (can add more rules here)
    return fuzz.ratio(name1, name2) / 100.0

def titles_honorifics(name1, name2):
    titles = ['dr', 'mr', 'phd', 'ms', 'mrs']
    name1_tokens = name1.split()
    name2_tokens = name2.split()
    for title in titles:
        if title in name1_tokens and title not in name2_tokens:
            name1_tokens.remove(title)
        elif title in name2_tokens and title not in name1_tokens:
            name2_tokens.remove(title)
    return fuzz.ratio(' '.join(name1_tokens), ' '.join(name2_tokens)) / 100.0

def missing_components(name1, name2):
    # Check if one name is a subset of the other
    return 1.0 if set(normalize_name(name1).split()).issubset(set(normalize_name(name2).split())) else 0.0

def out_of_order_components(name1, name2):
    # Check if names have the same components regardless of order
    return 1.0 if sorted(name1.split()) == sorted(name2.split()) else 0.0

def nicknames(name1, name2):
    nickname_dict = {
        "will": "william", 
        "bill": "william", 
        "billy": "william", 
        "james": "jim", 
        "jim": "james"
        # Add more nicknames as needed
    }
    for nickname, full_name in nickname_dict.items():
        if nickname in normalize_name(name1) or nickname in normalize_name(name2):
            return 1.0 if full_name in normalize_name(name1) or full_name in normalize_name(name2) else 0.0
    return 0.0

def initials(name1, name2):
    # Compare initials with full names
    name1_initials = ''.join([part[0] for part in name1.split() if part.isupper()])
    name2_initials = ''.join([part[0] for part in name2.split() if part.isupper()])
    return 1.0 if name1_initials == name2_initials else 0.0

def calculate_similarities(name1, name2):
    # Normalize names
    name1, name2 = normalize_name(name1), normalize_name(name2)

    # Calculate various similarity scores
    phonetic_sim = phonetic_similarity(name1, name2)
    missing_spaces_sim = missing_spaces_hyphens(name1, name2)
    spelling_sim = spelling_differences(name1, name2)
    titles_sim = titles_honorifics(name1, name2)
    missing_components_sim = missing_components(name1, name2)
    out_of_order_sim = out_of_order_components(name1, name2)
    nicknames_sim = nicknames(name1, name2)
    initials_sim = initials(name1, name2)

    # Combine similarity scores with weights
    weighted_score = (
        0.2 * phonetic_sim +
        0.2 * missing_spaces_sim +
        0.2 * spelling_sim +
        0.1 * titles_sim +
        0.1 * missing_components_sim +
        0.1 * out_of_order_sim +
        0.1 * nicknames_sim +
        0.1 * initials_sim
    )
    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'  # Replace with your desired output file path
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")

========================================  Code 5 ============================

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone
from itertools import permutations

# Load data from Excel
file_path = 'your_file.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    # Convert to lowercase, remove punctuations, extra spaces, etc.
    name = str(name).lower().replace(".", "").replace("-", "").replace(",", "")
    return name.strip()

def phonetic_encoding(name):
    # Using Double Metaphone for phonetic similarity
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

# Function to check if two names match by considering token order
def check_permutations_match(name1, name2):
    tokens1 = normalize_name(name1).split()
    tokens2 = normalize_name(name2).split()
    
    # If lengths differ significantly, they likely don't match
    if abs(len(tokens1) - len(tokens2)) > 1:
        return False

    # Check all permutations of tokens1 against tokens2
    for perm in permutations(tokens1):
        if " ".join(perm) == " ".join(tokens2):
            return True
    return False

# Similarity functions
def calculate_similarities(name1, name2):
    # Normalize names
    name1, name2 = normalize_name(name1), normalize_name(name2)

    # Check for out-of-order matches
    if check_permutations_match(name1, name2):
        return 1.0  # Return maximum score if they match in permutation
    
    # Phonetic similarity
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0
    
    # Edit distance similarity (Levenshtein)
    levenshtein_sim = fuzz.ratio(name1, name2) / 100.0
    
    # Jaro-Winkler similarity
    jaro_winkler_sim = fuzz.token_sort_ratio(name1, name2) / 100.0

    # Cosine similarity on character n-grams
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1, name2])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]

    # Weighted similarity score
    weighted_score = 0.3 * phonetic_sim + 0.3 * levenshtein_sim + 0.2 * jaro_winkler_sim + 0.2 * cosine_sim
    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'  # Replace with your desired output file path
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")



===================  code 6 ===========================================


import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'your_file.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    # Convert to lowercase, remove punctuations, extra spaces, etc.
    name = str(name).lower().replace(".", "").replace("-", "").replace(",", "")
    return name.strip()

def phonetic_encoding(name):
    # Using Double Metaphone for phonetic similarity
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

def remove_titles(name):
    # Remove common titles and honorifics
    titles = ["dr", "mr", "ms", "mrs", "phd", "prof", "hon"]
    name_tokens = name.split()
    name_tokens = [token for token in name_tokens if token not in titles]
    return " ".join(name_tokens)

def get_synonym(name):
    # Define nickname mapping for synonyms
    nickname_dict = {
        "william": ["will", "bill", "billy"],
        "joseph": ["joe"],
        "robert": ["rob", "bob", "bobby"],
        # Add more as needed
    }
    for main_name, nicknames in nickname_dict.items():
        if name in nicknames or name == main_name:
            return main_name
    return name

def calculate_similarities(name1, name2):
    # Normalize and preprocess names
    name1, name2 = normalize_name(name1), normalize_name(name2)
    name1, name2 = remove_titles(name1), remove_titles(name2)
    
    # Check if one name is a synonym of the other (nickname check)
    name1 = get_synonym(name1)
    name2 = get_synonym(name2)

    # Token-based similarity for out-of-order components
    tokens1, tokens2 = sorted(name1.split()), sorted(name2.split())
    if tokens1 == tokens2:
        return 1.0  # Full match for reordered components

    # Phonetic similarity
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0
    
    # Edit distance similarity (Levenshtein)
    levenshtein_sim = fuzz.ratio(name1, name2) / 100.0
    
    # Jaro-Winkler similarity
    jaro_winkler_sim = fuzz.token_sort_ratio(name1, name2) / 100.0

    # Cosine similarity on character n-grams
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1, name2])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]
    
    # Weighted similarity score with adjusted weights
    weighted_score = 0.35 * phonetic_sim + 0.25 * levenshtein_sim + 0.25 * jaro_winkler_sim + 0.15 * cosine_sim
    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.7):  # Increased threshold for higher precision
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.7)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'  # Replace with your desired output file path
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")




=====================   code 7 ( Nicknames ) ===============================

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'your_file.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    # Convert to lowercase, remove punctuations, extra spaces, etc.
    return str(name).lower().replace(".", "").replace("-", "").replace(",", "").strip()

def phonetic_encoding(name):
    # Using Double Metaphone for phonetic similarity
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

def approximate_nickname_match(name1, name2):
    # Short names match with longer names if they start similarly or are phonetic matches
    if len(name1) < len(name2):
        shorter, longer = name1, name2
    else:
        shorter, longer = name2, name1

    start_match = fuzz.partial_ratio(shorter, longer) >= 80
    phonetic_match = phonetic_encoding(shorter) == phonetic_encoding(longer[:len(shorter)])
    return start_match or phonetic_match

# Similarity functions
def calculate_similarities(name1, name2):
    # Normalize names
    name1, name2 = normalize_name(name1), normalize_name(name2)

    # Check for approximate nickname match
    if approximate_nickname_match(name1, name2):
        return 1.0  # Full match if approximate nickname match is found

    # Phonetic similarity
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0
    
    # Edit distance similarity (Levenshtein)
    levenshtein_sim = fuzz.ratio(name1, name2) / 100.0
    
    # Jaro-Winkler similarity
    jaro_winkler_sim = fuzz.token_sort_ratio(name1, name2) / 100.0

    # Cosine similarity on character n-grams
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1, name2])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]
    
    # Weighted similarity score
    weighted_score = 0.3 * phonetic_sim + 0.3 * levenshtein_sim + 0.2 * jaro_winkler_sim + 0.2 * cosine_sim
    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'  # Replace with your desired output file path
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")



=====================   Code 8 (initial ) =============================

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'your_file.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Preprocessing functions
def normalize_name(name):
    # Convert to lowercase, remove punctuations, extra spaces, etc.
    return str(name).lower().replace(".", "").replace("-", "").replace(",", "").strip()

def phonetic_encoding(name):
    # Using Double Metaphone for phonetic similarity
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

def extract_initials(name):
    """Extract initials from a name."""
    parts = name.split()
    return ''.join(part[0] for part in parts if part)

def approximate_nickname_match(name1, name2):
    # Short names match with longer names if they start similarly or are phonetic matches
    if len(name1) < len(name2):
        shorter, longer = name1, name2
    else:
        shorter, longer = name2, name1

    start_match = fuzz.partial_ratio(shorter, longer) >= 80
    phonetic_match = phonetic_encoding(shorter) == phonetic_encoding(longer[:len(shorter)])
    return start_match or phonetic_match

def initials_match(name1, name2):
    """Check for initials match."""
    initials1 = extract_initials(name1)
    initials2 = extract_initials(name2)
    return initials1 == initials2

# Similarity functions
def calculate_similarities(name1, name2):
    # Normalize names
    name1, name2 = normalize_name(name1), normalize_name(name2)

    # Check for initials match
    if initials_match(name1, name2):
        return 1.0  # Full match if initials match

    # Check for approximate nickname match
    if approximate_nickname_match(name1, name2):
        return 1.0  # Full match if approximate nickname match is found

    # Phonetic similarity
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1), phonetic_encoding(name2)) / 100.0
    
    # Edit distance similarity (Levenshtein)
    levenshtein_sim = fuzz.ratio(name1, name2) / 100.0
    
    # Jaro-Winkler similarity
    jaro_winkler_sim = fuzz.token_sort_ratio(name1, name2) / 100.0

    # Cosine similarity on character n-grams
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1, name2])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]
    
    # Weighted similarity score
    weighted_score = 0.3 * phonetic_sim + 0.3 * levenshtein_sim + 0.2 * jaro_winkler_sim + 0.2 * cosine_sim
    return weighted_score

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    # Convert results to a DataFrame
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'  # Replace with your desired output file path
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")
