====== Recall+Data preprocessing =====
import pandas as pd
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from fuzzywuzzy import fuzz
from metaphone import doublemetaphone

# Load data from Excel
file_path = 'Mathwizzathon_Entity_Matching_Dataset.xlsx'  # Replace with your Excel file path
data = pd.read_excel(file_path)

# Data Preprocessing
data = data.dropna(subset=['Name1', 'Name2'])  # Remove rows where 'Name1' or 'Name2' is missing
data['Name1'] = data['Name1'].str.strip().fillna('')  # Remove leading/trailing whitespace and fill NaNs with empty strings
data['Name2'] = data['Name2'].str.strip().fillna('')  # Remove leading/trailing whitespace and fill NaNs with empty strings

# List of common titles and honorifics to ignore
titles = {'dr', 'mr', 'mrs', 'ms', 'ph.d.', 'professor', 'sir', 'lady', 'captain', 'major'}

# Preprocessing functions
def normalize_name(name):
    return str(name).lower().replace(".", "").replace("-", "").replace(",", "").strip()

def remove_titles(name):
    parts = normalize_name(name).split()
    return ' '.join(part for part in parts if part not in titles)

def phonetic_encoding(name):
    encoded = doublemetaphone(name)
    return encoded[0] if encoded[0] else encoded[1]

def extract_initials(name):
    parts = name.split()
    return [part[0] for part in parts]

def initials_match(name1, name2):
    initials1 = set(extract_initials(name1))
    initials2 = set(extract_initials(name2))
    return initials1 == initials2

def approximate_nickname_match(name1, name2):
    if len(name1) < len(name2):
        shorter, longer = name1, name2
    else:
        shorter, longer = name2, name1

    # Reduced threshold to increase recall
    start_match = fuzz.partial_ratio(shorter, longer) >= 70
    phonetic_match = phonetic_encoding(shorter) == phonetic_encoding(longer[:len(shorter)])
    return start_match or phonetic_match

def has_common_components(name1, name2):
    components1 = set(name1.split())
    components2 = set(name2.split())
    return components1.issubset(components2) or components2.issubset(components1)

# Similarity functions
def calculate_similarities(name1, name2):
    name1, name2 = normalize_name(name1), normalize_name(name2)
    name1_no_titles = remove_titles(name1)
    name2_no_titles = remove_titles(name2)

    # Check for initials and nickname matches
    if initials_match(name1_no_titles, name2_no_titles) or approximate_nickname_match(name1_no_titles, name2_no_titles):
        return 1.0

    if has_common_components(name1_no_titles, name2_no_titles):
        return 0.9

    # Calculate different similarity scores
    phonetic_sim = fuzz.ratio(phonetic_encoding(name1_no_titles), phonetic_encoding(name2_no_titles)) / 100.0
    levenshtein_sim = fuzz.ratio(name1_no_titles, name2_no_titles) / 100.0
    jaro_winkler_sim = fuzz.token_sort_ratio(name1_no_titles, name2_no_titles) / 100.0

    vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))
    ngram_matrix = vectorizer.fit_transform([name1_no_titles, name2_no_titles])
    cosine_sim = cosine_similarity(ngram_matrix[0:1], ngram_matrix[1:2])[0][0]

    jaccard_sim = jaccard_similarity(name1_no_titles, name2_no_titles)

    # Adjusted weights to prioritize recall
    weighted_score = 0.25 * phonetic_sim + 0.25 * levenshtein_sim + 0.4 * jaro_winkler_sim + 0.3 * cosine_sim + 0.2 * jaccard_sim

    return weighted_score

def jaccard_similarity(name1, name2):
    set1, set2 = set(name1.split()), set(name2.split())
    return len(set1.intersection(set2)) / len(set1.union(set2))

# Matching function
def match_names_from_excel(data, threshold=0.6):
    results = []
    for _, row in data.iterrows():
        name1, name2 = row['Name1'], row['Name2']
        score = calculate_similarities(name1, name2)
        label = 1 if score >= threshold else 0
        results.append((name1, name2, score, label))
    
    results_df = pd.DataFrame(results, columns=["Name1", "Name2", "Similarity Score", "Predicted Label"])
    return results_df

# Run the matching and store the results
matched_df = match_names_from_excel(data, threshold=0.6)

# Add actual labels to the matched results for comparison
matched_df['Actual Label'] = data['Label']

# Calculate accuracy, precision, and recall
accuracy = (matched_df['Predicted Label'] == matched_df['Actual Label']).mean() * 100
precision = precision_score(matched_df['Actual Label'], matched_df['Predicted Label'])
recall = recall_score(matched_df['Actual Label'], matched_df['Predicted Label'])

# Identify mismatches
mismatches = matched_df[matched_df['Predicted Label'] != matched_df['Actual Label']]

# Print mismatched rows
if not mismatches.empty:
    print("Mismatches between Actual and Predicted Labels:")
    print(mismatches)
else:
    print("All predictions match the actual labels.")

# Save mismatches to a separate Excel file
mismatches_file_path = 'mismatched_names_output.xlsx'
mismatches.to_excel(mismatches_file_path, index=False)

# Save results to a new Excel file
output_file_path = 'matched_names_output.xlsx'
matched_df.to_excel(output_file_path, index=False)

print(f"Matched names saved to '{output_file_path}'")
print(f"Mismatched names saved to '{mismatches_file_path}'")
print(f"Accuracy: {accuracy:.2f}%")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
